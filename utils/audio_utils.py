from pydub import AudioSegment
import wave
import numpy as np
import soundfile as sf

print("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹:", wav_path)
print("ğŸ§ª ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º:", os.path.getsize(wav_path))

def convert_webm_to_wav(input_path, output_path):
    audio = AudioSegment.from_file(input_path, format="webm")
    audio.export(output_path, format="wav")

def convert_m4a_to_wav(input_path, output_path):
    import subprocess
    try:
        subprocess.run([
            'ffmpeg', '-y',
            '-i', input_path,
            '-acodec', 'pcm_s16le',  # æ˜ç¤ºçš„ã«ãƒªãƒ‹ã‚¢PCMã«å¤‰æ›
            '-ac', '1',              # ãƒ¢ãƒãƒ©ãƒ«
            '-ar', '44100',          # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‘¨æ³¢æ•°
            output_path
        ], check=True)
    except Exception as e:
        print("âŒ M4Aå¤‰æ›å¤±æ•—:", e)
        raise

def normalize_volume(input_path, output_path, target_dBFS=-5.0):
    audio = AudioSegment.from_file(input_path)
    change_in_dBFS = target_dBFS - audio.dBFS
    normalized_audio = audio.apply_gain(change_in_dBFS)
    normalized_audio.export(output_path, format="wav")

def is_valid_wav(wav_path, min_duration_sec=1.5):
    try:
        with wave.open(wav_path, 'rb') as wav_file:
            frames = wav_file.getnframes()
            rate = wav_file.getframerate()
            duration = frames / float(rate)
            print(f"ğŸ§ WAVé•·ã•: {duration:.2f}ç§’")
            return duration >= min_duration_sec
    except Exception as e:
        print("âŒ WAVãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã‚¨ãƒ©ãƒ¼:", e)
        return False

def analyze_stress_from_wav(wav_path):
    try:
        print("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹:", wav_path)
        import os
        print("ğŸ§ª ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º:", os.path.getsize(wav_path))

        audio = AudioSegment.from_wav(wav_path)
        print("ğŸ” audio.frame_rate:", audio.frame_rate)
        print("ğŸ” audio.channels:", audio.channels)
        print("ğŸ” audio.sample_width:", audio.sample_width)
        print("ğŸ” audio.duration_seconds:", len(audio) / 1000)
        print("ğŸ” len(audio.raw_data):", len(audio.raw_data))

        if len(audio.raw_data) == 0:
            raise ValueError("raw_dataãŒç©ºã§ã™")

        samples = np.frombuffer(audio.raw_data, dtype=np.int16).astype(np.float32)
        if samples.size == 0:
            raise ValueError("ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒ0ã§ã™")

        samples /= np.iinfo(np.int16).max

        duration = len(samples) / audio.frame_rate
        if duration < 1.5:
            return 50, True

        abs_audio = np.abs(samples)
        silence_ratio = float((abs_audio < 0.01).sum()) / len(abs_audio)
        if silence_ratio > 0.95:
            return 50, True

        volume_std = float(np.std(abs_audio))
        volume_std_scaled = np.clip(volume_std * 1500, 0, 100)
        voiced_ratio = 1 - silence_ratio
        voiced_scaled = np.clip(voiced_ratio * 100, 0, 100)

        score = round(np.clip(volume_std_scaled * 0.6 + voiced_scaled * 0.4, 30, 95))
        return score, False

    except Exception as e:
        print("âŒ analyze error:", e)
        return 50, True
