import wave, os, numpy as np, soundfile as sf
from pydub import AudioSegment

print("ğŸ¯ audio_utils path:", __file__)

def light_analyze(wav_path):
    """
    â‘ ã€œâ‘¢ ã®è¶…è»½é‡è§£æã ã‘ã‚’è¡Œã„ã€
    (score:int, is_fallback:bool) ã‚’è¿”ã™
    """
    # WAVèª­ã¿è¾¼ã¿ï¼šsoundfile â†’ pydub ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    try:
        y, sr = sf.read(wav_path, dtype='float32')
    except Exception:
        audio = AudioSegment.from_file(wav_path)
        arr = np.array(audio.get_array_of_samples()).astype(np.float32)
        sr = audio.frame_rate
        if audio.channels == 2:
            arr = arr.reshape((-1, 2)).mean(axis=1)
        y = arr

    # ç„¡éŸ³ãƒ»çŸ­æ™‚é–“ãƒã‚§ãƒƒã‚¯
    duration = len(y) / sr
    abs_y = np.abs(y)
    if duration < 1.5 or np.mean(abs_y < 0.01) > 0.95:
        return 50, True

    # â‘  å£°é‡å¤‰å‹•ï¼ˆæŒ¯å¹…STDï¼‰
    vol_std = float(np.std(abs_y))

    # â‘¡ æœ‰å£°éŸ³ç‡ï¼ˆå˜ç´”é–¾å€¤ï¼‰
    voiced_ratio = float((abs_y > 0.02).sum()) / len(abs_y)

    # â‘¢ ã‚¼ãƒ­äº¤å·®ç‡ï¼ˆé«˜é€Ÿè¨ˆç®—ï¼‰
    zero_crossings = ((y[:-1] * y[1:]) < 0).sum()
    zcr = float(zero_crossings) / len(y)

    # 0â€“100 ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    vol_s   = np.clip(vol_std   * 1500, 0, 100)
    voice_s = np.clip(voiced_ratio * 120, 0, 100)
    zcr_s   = np.clip(zcr          * 100, 0, 100)

    # é‡ã¿ã¥ã‘
    raw = vol_s * 0.4 + voice_s * 0.4 + zcr_s * 0.2
    score = round(np.clip(raw, 30, 95))
    return score, False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ã“ã“ã‹ã‚‰ã‚¹ã‚³ã‚¢è§£æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def analyze_stress_from_wav(wav_path):
    """
    return (score:int, is_fallback:bool)
    30â€“95 ç‚¹ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    """
    try:
        y, sr = sf.read(wav_path, dtype='float32')
        if y.ndim == 2:
            y = y.mean(axis=1)
        if y.size == 0:
            raise ValueError("empty")

        duration = y.size / sr
        abs_y    = np.abs(y)
        silence_ratio = np.mean(abs_y < 0.01)

        if duration < 1.5 or silence_ratio > 0.95:
            return 50, True

        # ---------- â‘  å£°é‡å¤‰å‹• ----------
        volume_std = np.std(abs_y)

        # ---------- â‘¡ ç²¾å¯† Voiced ç‡ ----------
        intervals = librosa.effects.split(y, top_db=40)
        voiced_dur = sum(e - s for s, e in intervals) / sr
        voiced_ratio = voiced_dur / duration

        # ---------- â‘¢ ã‚¼ãƒ­äº¤å·®ç‡ ----------
        zcr = librosa.feature.zero_crossing_rate(y, frame_length=2048, hop_length=512).mean()

        # ---------- â‘£ ãƒ”ãƒƒãƒæ¨™æº–åå·® ----------
        pitches, mags = librosa.piptrack(y=y, sr=sr)
        p = pitches[mags > np.median(mags)]
        pitch_std = np.std(p) if p.size else 0.0

        # ---------- â‘¤ ãƒ†ãƒ³ãƒï¼ˆéŸ³ç¯€/ç§’è¿‘ä¼¼ï¼‰ ----------
        onset_frames = librosa.onset.onset_detect(y=y, sr=sr, units='frames')
        onset_times  = librosa.frames_to_time(onset_frames, sr=sr)
        if len(onset_times) > 1:
            tempo_val = len(onset_times) / (onset_times[-1] - onset_times[0])
        else:
            tempo_val = 0.0

        # ============ ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚° 0-100 ============
        vol_scaled   = np.clip(volume_std   * 1500, 0, 100)
        voice_scaled = np.clip(voiced_ratio * 120, 0, 100)
        zcr_scaled   = np.clip(zcr          * 5000, 0, 100)
        pitch_scaled = np.clip(pitch_std    * 0.05, 0, 100)
        tempo_scaled = 100 - np.clip(abs(tempo_val - 5) * 20, 0, 100)  # 5 éŸ³ç¯€/ç§’ã‚’ä¸­å¿ƒã«

        # ============ é‡ã¿ã¥ã‘ ============
        score_raw = (
              vol_scaled   * 0.25
            + voice_scaled * 0.25
            + zcr_scaled   * 0.15
            + pitch_scaled * 0.15
            + tempo_scaled * 0.20
        )
        score = round(np.clip(score_raw, 30, 95))   # ä¸Šé™ã¯ 95 ã®ã¾ã¾
        return score, False

    except Exception as e:
        print("âŒ analyze error:", e)
        return 50, True
